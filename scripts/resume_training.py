import os
import sys
import gymnasium as gym
import numpy as np
import torch
from stable_baselines3 import SAC
from stable_baselines3.common.callbacks import CheckpointCallback
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.vec_env import DummyVecEnv

# ==============================================================================
# ğŸŸ¢ è·¯å¾„è®¾ç½® (ä¿æŒå’Œä½ è®­ç»ƒè„šæœ¬ä¸€è‡´)
# ==============================================================================
current_file_path = os.path.abspath(__file__)
script_dir = os.path.dirname(current_file_path)
project_root = os.path.dirname(script_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å¯¼å…¥ä½ çš„ç¯å¢ƒ
try:
    from scripts.residual_env import ResidualPegEnv
except ImportError:
    from residual_env import ResidualPegEnv

def main():
    # ==============================================================================
    # âš™ï¸ [é…ç½®åŒºåŸŸ] - è¯·æ ¹æ®ä½ çš„éœ€æ±‚ä¿®æ”¹è¿™é‡Œ
    # ==============================================================================
    
    # 1. åœºæ™¯é€‰æ‹© (æ˜¯"æ–­ç‚¹ç»­è®­"è¿˜æ˜¯"æ–°ä¸€è½®Round"?)
    # True  = å¼€å¯ Round 4 (é‡ç½®æ­¥æ•°ï¼Œä¸åŠ è½½æ—§ Bufferï¼Œåº”ç”¨æ–° Scale)
    # False = çº¯æ–­ç‚¹ç»­è®­ (æ¥ä¸Šä¹‹å‰çš„æ­¥æ•°å’Œ Bufferï¼Œå‚æ•°ä¸å˜)
    START_NEW_ROUND = True 

    # 2. è·¯å¾„é…ç½®
    # ä¸Šä¸€è½®è®­ç»ƒå¥½çš„æ¨¡å‹ (.zip)
    LOAD_MODEL_PATH = os.path.join(project_root, "data/models/SAC_Residual_v1/rl_model_105000_steps.zip") # ğŸ‘ˆ ä¿®æ”¹è¿™é‡ŒæŒ‡å‘ä½ çš„ checkpoint
    
    # ä¸Šä¸€è½®çš„ Replay Buffer (å¦‚æœ START_NEW_ROUND=Trueï¼Œè¿™ä¸ªé€šå¸¸ä¸ç”¨å¡«ï¼Œé™¤éä½ æƒ³å¤ç”¨ç»éªŒ)
    LOAD_REPLAY_BUFFER = False 
    REPLAY_BUFFER_PATH = os.path.join(project_root, "data/models/SAC_Residual_v1/rl_model_replay_buffer_100000_steps.pkl")

    # Base Policy è·¯å¾„ (ä¿æŒä¸å˜)
    CKPT_RELATIVE_PATH = "diffusion_policy/data/outputs/2026.01.26/16.00.38_train_diffusion_unet_hybrid_peg_in_hole/checkpoints/base_policy.ckpt"
    BASE_CKPT_PATH = os.path.join(project_root, CKPT_RELATIVE_PATH)

    # 3. æ–°ä¸€è½®å‚æ•° (Round 4 é…ç½®)
    NEW_RUN_NAME = "SAC_Residual_v2"  # æ–°çš„ Log åå­—
    NEW_TOTAL_TIMESTEPS = 200_000      # æ–°ä¸€è½®è·‘å¤šå°‘æ­¥
    
    # ğŸ‘‰ [å…³é”®ä¿®æ”¹] Round 4 æˆ‘ä»¬æŠŠ Scale åŠ å¤§åˆ° 0.03
    NEW_RESIDUAL_SCALE = 0.02 if START_NEW_ROUND else 0.01 
    
    # å…¶ä»–ç¯å¢ƒå‚æ•° (ä¿æŒå’Œè®­ç»ƒè„šæœ¬ä¸€è‡´)
    ACTION_CHUNK_SIZE = 4
    MAX_STEPS = 200     # è®­ç»ƒè„šæœ¬é‡Œä½ æ”¹æˆäº† 200
    RESIDUAL_CLIP = 0.2

    # ==============================================================================
    # ğŸš€ è„šæœ¬é€»è¾‘å¼€å§‹
    # ==============================================================================
    
    # 1. æ£€æŸ¥ Base Policy
    if not os.path.exists(BASE_CKPT_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° Base Policy æ–‡ä»¶: {BASE_CKPT_PATH}")
        return

    # 2. åˆ›å»ºç¯å¢ƒ (Factory æ¨¡å¼ï¼Œé€‚é… VecEnv)
    print(f"ğŸ”§ åˆå§‹åŒ–ç¯å¢ƒ: Scale = {NEW_RESIDUAL_SCALE}, Steps = {MAX_STEPS}")
    
    def make_env():
        env = ResidualPegEnv(
            base_ckpt_path=BASE_CKPT_PATH,
            residual_scale=NEW_RESIDUAL_SCALE,  # <--- åº”ç”¨æ–°çš„ Scale
            residual_clip=RESIDUAL_CLIP,
            action_chunk_size=ACTION_CHUNK_SIZE,
            max_steps=MAX_STEPS,
            device='cuda:0'
        )
        # è®¾ç½® Monitor è®°å½• Log
        log_dir = os.path.join(project_root, "data", "logs", NEW_RUN_NAME)
        os.makedirs(log_dir, exist_ok=True)
        return Monitor(env, log_dir)

    # åŒ…è£…æˆ DummyVecEnv (éå¸¸é‡è¦ï¼å› ä¸º SAC.load éœ€è¦ç¯å¢ƒç»“æ„åŒ¹é…)
    env = DummyVecEnv([make_env])

    # 3. åŠ è½½æ¨¡å‹
    print(f"ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹: {LOAD_MODEL_PATH}")
    # custom_objects å¯ä»¥ç”¨æ¥è¦†ç›–æ—§æ¨¡å‹é‡Œçš„ä¸€äº›å‚æ•°ï¼Œä½†è¿™é‡Œæˆ‘ä»¬ä¸»è¦é ç¯å¢ƒæ”¹å˜
    model = SAC.load(
        LOAD_MODEL_PATH, 
        env=env, 
        device='cuda:0',
        print_system_info=True
    )

    # 4. å¤„ç† Replay Buffer
    if LOAD_REPLAY_BUFFER and not START_NEW_ROUND:
        if os.path.exists(REPLAY_BUFFER_PATH):
            print(f"ğŸ“¥ æ­£åœ¨åŠ è½½ Replay Buffer: {REPLAY_BUFFER_PATH}")
            model.load_replay_buffer(REPLAY_BUFFER_PATH)
            print(f"âœ… Buffer åŠ è½½å®Œæˆï¼Œå½“å‰å¤§å°: {model.replay_buffer.size()}")
        else:
            print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ° Buffer æ–‡ä»¶ {REPLAY_BUFFER_PATH}ï¼Œå°†ä»ç©º Buffer å¼€å§‹ã€‚")
    else:
        print("ğŸ†• å¼€å¯æ–°ä¸€è½® / ä¸åŠ è½½æ—§ Bufferï¼Œå°†ä»ç©º Buffer å¼€å§‹é‡æ–°æ”¶é›†é€‚åº”æ–° Scale çš„æ•°æ®ã€‚")

    # 5. è®¾ç½®å›è°ƒå‡½æ•°
    save_dir = os.path.join(project_root, "data", "models", NEW_RUN_NAME)
    checkpoint_callback = CheckpointCallback(
        save_freq=5000,
        save_path=save_dir,
        name_prefix="rl_model"
    )

    # 6. å¼€å§‹è®­ç»ƒ
    # reset_num_timesteps=True: Tensorboard ä» 0 å¼€å§‹ç”»æ–°å›¾ (é€‚åˆ Round 4)
    # reset_num_timesteps=False: æ¥åœ¨æ—§å›¾åé¢ (é€‚åˆæ–­ç‚¹ç»­è®­)
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ: {NEW_RUN_NAME}")
    print(f"ğŸ¯ ç›®æ ‡æ­¥æ•°: {NEW_TOTAL_TIMESTEPS}")
    print(f"ğŸ“ˆ Tensorboard Log: data/logs/{NEW_RUN_NAME}")

    try:
        model.learn(
            total_timesteps=NEW_TOTAL_TIMESTEPS,
            callback=[checkpoint_callback],
            tb_log_name=NEW_RUN_NAME,
            reset_num_timesteps=START_NEW_ROUND, 
            progress_bar=True
        )
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·æ‰‹åŠ¨åœæ­¢è®­ç»ƒï¼Œæ­£åœ¨ä¿å­˜æœ€åä¸€æ­¥...")

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    model.save(os.path.join(save_dir, "rl_model_final"))
    print("âœ… ç»­è®­/å¾®è°ƒç»“æŸï¼")
    env.close()

if __name__ == "__main__":
    main()